{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/CS167-sp24-notes/blob/main/Day23_Recurrent_Neural_Network_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS167: Day23\n",
        "## Deep Learning and Recurrent Neural Network (RNN)\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2024\n",
        "\n",
        "Thursday, April 25th, 2024\n",
        "\n",
        "ðŸ“† [Course Schedule](https://analytics.drake.edu/~reza/teaching/cs167_sp24/cs167_schedule.html) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs167_sp24/cs167_syllabus_sp24.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources:\n",
        "\n",
        "- [Understanding LSTM](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [Unreasonable Effectiveness of RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness)\n",
        "- [Intro to RNNs](https://towardsdatascience.com/a-brief-introduction-to-recurrent-neural-networks-638f64a61ff4)\n"
      ],
      "metadata": {
        "id": "ObKtx5ooywoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Put the Model on Training Device (GPU or CPU)__\n",
        "We want to accelerate the training process using graphical processing unit (GPU). Fortunately, in Colab we can access for GPU. You need to enable it from _Runtime-->Change runtime type-->GPU or TPU_"
      ],
      "metadata": {
        "id": "OpvuEwrzrVe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import numpy as np\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFa7eTujrik7",
        "outputId": "bb1c22d6-c6e2-4ec7-8f1c-130d52e831bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Load the Dataset for your RNN__"
      ],
      "metadata": {
        "id": "82757Boz0u5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Download this text file -- _shakespeare_text.txt_](https://analytics.drake.edu/~reza/teaching/cs167_fall23/dataset/shakespeare_text.txt)\n",
        "- Then, put it in your Google Drive."
      ],
      "metadata": {
        "id": "dDGk01A804vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wepLktbnS7T",
        "outputId": "93cc6154-0082-4f12-841d-0aad4eaefb71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'shakespeare_text'\n",
        "path = '/content/drive/MyDrive/cs167_sp24/datasets/' + file_name + '.txt'\n",
        "with open(path, 'r') as file:\n",
        "  text_data = file.read() # read the entire text as a big string\n",
        "\n",
        "text_vocab = sorted(set(text_data.lower()))\n",
        "vocab_size = len(text_vocab)\n",
        "print(\"Vocabulary (referring to the alphabets representing your text data): \", text_vocab) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "print(\"Vocabulary size (number of letters in your alphabets): \", vocab_size) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "text_data_size = len(text_data)\n",
        "print(\"Total number of letters (or characters) in the dataset: \", text_data_size)\n",
        "print(\"\")\n"
      ],
      "metadata": {
        "id": "4kz7QVYF1ECa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c276fc-c970-44b7-c91c-f53386300cc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (referring to the alphabets representing your text data):  ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "\n",
            "Vocabulary size (number of letters in your alphabets):  39\n",
            "\n",
            "Total number of letters (or characters) in the dataset:  1115394\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explore some sample training images__"
      ],
      "metadata": {
        "id": "3rcoqtTu1JH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a random set of text ...\n",
        "for i in range(100):\n",
        "  print(text_data[i].lower(), end=\"\")"
      ],
      "metadata": {
        "id": "rNVp5mR51Lo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87318c40-325b-470c-fcc5-5d3ee23f4fbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first citizen:\n",
            "before we proceed any further, hear me speak.\n",
            "\n",
            "all:\n",
            "speak, speak.\n",
            "\n",
            "first citizen:\n",
            "you"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Prepare Your Data for Training__\n"
      ],
      "metadata": {
        "id": "5w26ZMYs1vL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: create a mapping between the characters in our voculary to a set of numeric indices\n",
        "def convert_vocab_to_index(vocab):\n",
        "  vocab_to_index_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    vocab_to_index_dict[char] = index\n",
        "  return vocab_to_index_dict\n",
        "\n",
        "def convert_index_to_vocab(vocab):\n",
        "  index_to_vocab_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    index_to_vocab_dict[index] = char\n",
        "  return index_to_vocab_dict\n",
        "\n",
        "\n",
        "vocab_to_index_dict = convert_vocab_to_index(text_vocab)\n",
        "index_to_vocab_dict = convert_index_to_vocab(text_vocab)\n",
        "\n",
        "\n",
        "# Step 2: convert the text_data to numeric numbers using the above conversion method (this mapped data will be used for training)\n",
        "text_data_numeric_values = np.zeros(text_data_size)\n",
        "for i in range(text_data_size):\n",
        "  cur_character = text_data[i].lower()\n",
        "  text_data_numeric_values[i] = vocab_to_index_dict[cur_character]\n",
        "\n",
        "# Step 3: visualize the first few characters in our text_data\n",
        "for i in range(6):\n",
        "  print(\"character: \", text_data[i].lower(), \" encoded as: \", text_data_numeric_values[i])"
      ],
      "metadata": {
        "id": "x9hHtMpu130p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d24f9f-b2c9-4b10-d788-7fd91cbfbb28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "character:  f  encoded as:  18.0\n",
            "character:  i  encoded as:  21.0\n",
            "character:  r  encoded as:  30.0\n",
            "character:  s  encoded as:  31.0\n",
            "character:  t  encoded as:  32.0\n",
            "character:     encoded as:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also see the reverse encoding of the first few characters in our text_data\n",
        "encoding = [18, 21, 30, 31, 32, 1]\n",
        "for i in range(len(encoding)):\n",
        "  cur_character = index_to_vocab_dict[encoding[i]]\n",
        "  print(\"encoding: \", encoding[i], \" and the corresponding character is: \", cur_character)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oftHytw3B1-",
        "outputId": "d4716f96-7ea7-435d-9c0d-4b8db119a2b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoding:  18  and the corresponding character is:  f\n",
            "encoding:  21  and the corresponding character is:  i\n",
            "encoding:  30  and the corresponding character is:  r\n",
            "encoding:  31  and the corresponding character is:  s\n",
            "encoding:  32  and the corresponding character is:  t\n",
            "encoding:  1  and the corresponding character is:   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the encoded numbers into tensor data types in PyTorch\n",
        "#train_data = torch.from_numpy(text_data_numeric_values).to(device)\n",
        "train_data = torch.LongTensor(text_data_numeric_values).to(device)"
      ],
      "metadata": {
        "id": "DcNcua-X4aoq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-bd6k9440D1",
        "outputId": "09f0e22a-448b-4758-8d22-2cda14eb2217"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 21, 30,  ..., 19,  8,  0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.unsqueeze(train_data, dim=1) # make each number a separate sample for training\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QmvUx0T5EFB",
        "outputId": "4f7446b6-db05-402a-c885-7016e726411d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[18],\n",
              "        [21],\n",
              "        [30],\n",
              "        ...,\n",
              "        [19],\n",
              "        [ 8],\n",
              "        [ 0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Building Recurrent Neural Network (RNN)__\n",
        "\n",
        "Create a network class with two methods:\n",
        "- _init()_\n",
        "- _forward()_\n"
      ],
      "metadata": {
        "id": "q4pTsgDsTEiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# You can give any name to your new network, e.g., SimpleRNN.\n",
        "# However, you have to mandatorily inherit from nn.Module to\n",
        "# create your own network class. That way, you can access a lot of\n",
        "# useful methods and attributes from the parent class nn.Module\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "    # ...\n",
        "    # ...\n",
        "\n",
        "  def forward(self, x):\n",
        "    # your code for RNN forward pass should take place here\n",
        "    # ...\n",
        "    # ...\n",
        "    return x"
      ],
      "metadata": {
        "id": "9DxGu6AUTW10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the RNN as shown in the picture above using this template. In general, we will follow this template for constructing other neural networks such as MLP, CNN, RNN, and Transformer in PyTorch. Hence, it is a very generic setup. Here are the useful PyTorch modules we will be using for RNN construction:\n",
        "\n",
        "- [nn.Embedding()](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "  - __num_embeddings__: size of the dictionary of embeddings\n",
        "  - __embedding_dim__: the size of each embedding vector\n",
        "  - e.g., _nn.Embedding(39, 39)_ will create a dictionary of 39 embedding vectors where each vector is represented with 39 floating point numbers\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp24/notes/embedding.png\" width=400/>\n",
        "</div>\n",
        "  - during forward pass, you should provide as input __a list of indices__, and the output is the corresponding word embeddings.\n",
        "- [nn.LSTM()](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
      ],
      "metadata": {
        "id": "ww0jFonlZh4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pdb\n",
        "\n",
        "# You can give any name to your new network, e.g., SimpleRNN based on LSTM\n",
        "class SimpleRNNv1(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "\n",
        "    # add an embedding layer which will convert index to a raw character let's\n",
        "    # say (1 which stands for 'a') or (2 which stands for 'b') or (3 which stands for 'c')\n",
        "    # to a vector [or length vocab_size] for that character\n",
        "    self.embedding        = nn.Embedding(vocab_size, vocab_size)\n",
        "    self.lstm             = nn.LSTM(input_size=vocab_size, hidden_size=hidden_size, num_layers=3)\n",
        "    self.classifier       = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x_sequence, hidden_state):\n",
        "    # your code for RNN forward pass should take place here\n",
        "    embedded_code         = self.embedding(x_sequence)\n",
        "    output, hidden_state  = self.lstm(embedded_code, hidden_state)\n",
        "    output                = self.classifier(output)\n",
        "\n",
        "    return output, (hidden_state[0].detach(), hidden_state[1].detach())\n"
      ],
      "metadata": {
        "id": "HNuxDcIFYjY6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the structure of your RNN\n",
        "\n",
        "rnn_model = SimpleRNNv1(vocab_size, 512, vocab_size)\n",
        "rnn_model.to(device)\n",
        "print(rnn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwRblRgmVlv",
        "outputId": "7e1235de-7c45-40f1-caa2-28df3128d110"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleRNNv1(\n",
            "  (embedding): Embedding(39, 39)\n",
            "  (lstm): LSTM(39, 512, num_layers=3)\n",
            "  (classifier): Linear(in_features=512, out_features=39, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Forward Pass using your Dataset and your RNN__\n",
        "Test a forward pass of our first RNN using one of the training samples.\n",
        "The forward method inside our network class, __SimpleRNNv1__, will be invoked if we provide an input tensor __X__ to the network object we instantiated earlier, i.e., __rnn_model__, as follows:\n",
        "- _output = rnn_model(X)_\n"
      ],
      "metadata": {
        "id": "HGToEDVFl9rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_index     = 0\n",
        "sequence_length = 100                                                        # if the sequence of text is      :  ['f', 'i', 'r', 's', 't', ' ', 's', 'e', 'n', 't', 'e', 'n', 'c', 'e', ...]\n",
        "input_sequence  = train_data[start_index:   start_index+sequence_length]     # if the given input sequence is  :  ['f', 'i', 'r', 's', 't']\n",
        "output_sequence = train_data[start_index+1: start_index+1+sequence_length]   # then expected output sequence is:  ['i', 'r', 's', 't', ' '] ie, next letter prediction\n",
        "\n",
        "# forward pass of our RNN\n",
        "hidden_state         = None\n",
        "output, hidden_state = rnn_model(input_sequence, hidden_state)\n",
        "print(\"output shape: \", output.shape)\n",
        "print(\"output mapping for the 1st-character: \\n\", output[0,:]) #\n",
        "print(\"output mapping for the 2nd-character: \\n\", output[1,:]) #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OQed_nsazcw",
        "outputId": "ffc90c43-c84d-42f2-ad73-b60d48686093"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape:  torch.Size([100, 1, 39])\n",
            "output mapping for the 1st-character: \n",
            " tensor([[-0.0050, -0.0340,  0.0337,  0.0148, -0.0102, -0.0389, -0.0205, -0.0452,\n",
            "          0.0242,  0.0201,  0.0209,  0.0207,  0.0009, -0.0359, -0.0043,  0.0113,\n",
            "          0.0198,  0.0235, -0.0412,  0.0028,  0.0329, -0.0123,  0.0004,  0.0016,\n",
            "          0.0352,  0.0050, -0.0411, -0.0155, -0.0311,  0.0102, -0.0141,  0.0142,\n",
            "         -0.0229,  0.0344, -0.0052, -0.0239, -0.0322, -0.0246, -0.0059]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "output mapping for the 2nd-character: \n",
            " tensor([[-0.0104, -0.0330,  0.0360,  0.0162, -0.0041, -0.0381, -0.0180, -0.0467,\n",
            "          0.0253,  0.0253,  0.0210,  0.0241,  0.0018, -0.0345, -0.0013,  0.0065,\n",
            "          0.0216,  0.0254, -0.0447,  0.0005,  0.0350, -0.0139, -0.0045,  0.0024,\n",
            "          0.0368,  0.0078, -0.0386, -0.0161, -0.0350,  0.0124, -0.0157,  0.0121,\n",
            "         -0.0272,  0.0358, -0.0024, -0.0299, -0.0319, -0.0271, -0.0112]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Defining Loss function__\n",
        "\n",
        "- [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n",
        "  - useful when training a __classification problem__ with __C__ classes.\n",
        "  - criterion computes the cross entropy loss between input logits and target"
      ],
      "metadata": {
        "id": "f1gTfGDJm-2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss() # this is useful for multiclass classification task"
      ],
      "metadata": {
        "id": "OK1bAAANnLMz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Initializing the Optimizer__\n",
        "\n",
        "Optimiztaion, as we have discussed in previous week, is process of adjusting model parameters to reduce model error in each training step. PyTorch provides a selection of optimization algorithms in the [torch.optim](https://pytorch.org/docs/stable/optim.html) package. Some of them are as follows:\n",
        "- [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "- [torch.optim..Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- [torch.optim.RMSprop](https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html#torch.optim.RMSprop)\n",
        "\n",
        "In addition to selecting the optimizer, we can also select the yperparameters which are refered to as adjustable parameters crucial for controlling the model optimization process. You can influence the training and convergence of the model by tweaking these hyperparameters:\n",
        "- __epochs:__ denotes the number of iterations over the dataset\n",
        "- __batch size:__ represents the quantity of data samples in each iteration propagated through the network before updating the parameters\n",
        "- __learning rate:__ determines the extent of parameter updates made at each batch/epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "J6Mwh6U1mGev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-3\n",
        "batch_size    = 1\n",
        "epochs        = 10\n",
        "# let's use ADAM optimization algorithm for training our model\n",
        "optimizer     = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "11-Lj-avlzFo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Putting Everything Together RNN__"
      ],
      "metadata": {
        "id": "Z7yBVqvGmQM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Putting Everything Together using our SimpleRNNv1 Network on Shakespeare Dataset__\n"
      ],
      "metadata": {
        "id": "Xn0KYm8r1i1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat\n",
        "import pdb\n",
        "import time\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "\n",
        "# Step 2: load the dataset, ie, we are experimenting with Shakespeare text\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "file_name = 'shakespeare_text'\n",
        "path = '/content/drive/MyDrive/cs167_sp24/datasets/' + file_name + '.txt' # you can download the text file from Blackboard --> datasets\n",
        "with open(path, 'r') as file:\n",
        "  text_data = file.read() # read the entire text as a big string\n",
        "\n",
        "text_vocab = sorted(set(text_data.lower()))\n",
        "vocab_size = len(text_vocab)\n",
        "print(\"Vocabulary (referring to the alphabets present in your text data): \", text_vocab) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "print(\"Vocabulary size (referring to the alphabets present in your text data): \", vocab_size) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "text_data_size = len(text_data)\n",
        "print(\"Total number of letters (or characters) in the dataset: \", text_data_size)\n",
        "print(\"\")\n",
        "\n",
        "# First: create a mapping between the characters in our voculary to a set of numeric indices\n",
        "def convert_vocab_to_index(vocab):\n",
        "  vocab_to_index_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    vocab_to_index_dict[char] = index\n",
        "  return vocab_to_index_dict\n",
        "\n",
        "def convert_index_to_vocab(vocab):\n",
        "  index_to_vocab_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    index_to_vocab_dict[index] = char\n",
        "  return index_to_vocab_dict\n",
        "\n",
        "\n",
        "vocab_to_index_dict = convert_vocab_to_index(text_vocab)\n",
        "index_to_vocab_dict = convert_index_to_vocab(text_vocab)\n",
        "\n",
        "\n",
        "# Second: convert the text_data to numeric numbers using the above conversion method (this mapped data will be used for training)\n",
        "text_data_numeric_values = np.zeros(text_data_size)\n",
        "for i in range(text_data_size):\n",
        "  cur_character = text_data[i].lower()\n",
        "  text_data_numeric_values[i] = vocab_to_index_dict[cur_character]\n",
        "\n",
        "# Third: convert to tensor datatype\n",
        "\n",
        "train_data = torch.LongTensor(text_data_numeric_values).to(device)\n",
        "train_data = torch.unsqueeze(train_data, dim=1) # make each number a separate sample for training by putting them in a separate inner list\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Create your RNN Network (call it SimpleRNNv1) with 1 embedding layer + 3 layers of LSTM module\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "# You can give any name to your new network, e.g., SimpleRNN based on LSTM\n",
        "# However, you have to mandatorily inherit from nn.Module to\n",
        "# create your own network class. That way, you can access a lot of\n",
        "# useful methods and attributes from the parent class nn.Module\n",
        "\n",
        "class SimpleRNNv1(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "\n",
        "    # add an embedding layer which will convert index to a raw character let's say (1 which stands for 'a') or (2 which stands for 'b') or (3 which stands for 'c') to a vector [or length vocab_size] for that character\n",
        "    self.embedding        = nn.Embedding(vocab_size, vocab_size)\n",
        "    self.lstm             = nn.LSTM(input_size=vocab_size, hidden_size=hidden_size, num_layers=3)\n",
        "    self.classifier       = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x_sequence, hidden_state):\n",
        "    # your code for RNN forward pass should take place here\n",
        "    embedded_code         = self.embedding(x_sequence)\n",
        "    output, hidden_state  = self.lstm(embedded_code, hidden_state)\n",
        "    output                = self.classifier(output)\n",
        "\n",
        "    return output, (hidden_state[0].detach(), hidden_state[1].detach())\n",
        "\n",
        "\n",
        "# check the structure of your RNN\n",
        "rnn_model = SimpleRNNv1(vocab_size, 512, vocab_size)\n",
        "rnn_model.to(device)\n",
        "print(rnn_model)\n",
        "\n",
        "# Step 4: Your training function\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def train_loop(model, loss_fn, optimizer, save_path):\n",
        "\n",
        "  sequence_length = 100\n",
        "  train_loss      = 0\n",
        "  hidden_state    = None\n",
        "  random_index    = np.random.randint(sequence_length)\n",
        "  iteration       = 0\n",
        "\n",
        "  for start_index in range(random_index, len(train_data)-sequence_length, sequence_length):\n",
        "    #pdb.set_trace()\n",
        "\n",
        "    input_sequence        = train_data[start_index:   start_index+sequence_length]     # eg, if the input sequence is: ['f', 'i', 'r', 's', 't']\n",
        "    gt_output_sequence    = train_data[start_index+1: start_index+1+sequence_length]   #  then the output sequence is: ['i', 'r', 's', 't', ' '] ie, next letter prediction\n",
        "\n",
        "    # compute prediction and loss\n",
        "    output_sequence, hidden_state   = model(input_sequence, hidden_state)\n",
        "    loss                            = loss_fn(torch.squeeze(output_sequence), torch.squeeze(gt_output_sequence))\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    iteration  += 1\n",
        "\n",
        "\n",
        "  print(f\"loss: {train_loss/iteration:>7f}\")\n",
        "  torch.save(model.state_dict(), save_path)\n",
        "\n",
        "  return train_loss/iteration\n",
        "\n",
        "\n",
        "# Step 5: select your optimizer and set the hyper-parameters for learning the model\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "learning_rate = 2e-3\n",
        "epochs        = 10\n",
        "loss_fn       = nn.CrossEntropyLoss()\n",
        "optimizer     = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate) # let's use ADAM optimization algorithm for training our model\n",
        "\n",
        "train_losses   = []\n",
        "save_path      = '/content/drive/MyDrive/cs167_fall23/datasets/rnn_model_' + file_name + '.pth'\n",
        "loss_save_path = '/content/drive/MyDrive/cs167_fall23/datasets/rnn_model_' + file_name + '_losses.mat'\n",
        "t0 = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    avg_train_loss = train_loop(rnn_model, loss_fn, optimizer, save_path)\n",
        "    # save the losses and accuracies\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"completed in {(time.time()-t0)/60:.3f} minutes\")\n",
        "print(\"SimpleRNNv1 model has been trained!\")\n",
        "savemat(loss_save_path, {'train_losses':train_losses})\n"
      ],
      "metadata": {
        "id": "TE6r3j-71vjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59179f5e-ae95-40da-ff5f-e8de958d15d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Vocabulary (referring to the alphabets present in your text data):  ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "\n",
            "Vocabulary size (referring to the alphabets present in your text data):  39\n",
            "\n",
            "Total number of letters (or characters) in the dataset:  1115394\n",
            "\n",
            "SimpleRNNv1(\n",
            "  (embedding): Embedding(39, 39)\n",
            "  (lstm): LSTM(39, 512, num_layers=3)\n",
            "  (classifier): Linear(in_features=512, out_features=39, bias=True)\n",
            ")\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.497125\n",
            "completed in 2.785 minutes\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.347375\n",
            "completed in 5.598 minutes\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.325131\n",
            "completed in 8.361 minutes\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.313675\n",
            "completed in 11.113 minutes\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.306688\n",
            "completed in 13.860 minutes\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.299119\n",
            "completed in 16.606 minutes\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.289225\n",
            "completed in 19.356 minutes\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.282728\n",
            "completed in 22.106 minutes\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.278558\n",
            "completed in 24.856 minutes\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.271841\n",
            "completed in 27.603 minutes\n",
            "SimpleRNNv1 model has been trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the training loss curve\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat, loadmat\n",
        "loss_save_path = '/content/drive/MyDrive/cs167_sp24/datasets/rnn_model_' + file_name + '_losses.mat'\n",
        "res = loadmat(loss_save_path)\n",
        "train_losses = res['train_losses'][0]\n",
        "vis = 1\n",
        "if vis:\n",
        "    plt.plot(range(1,len(train_losses)+1), train_losses)\n",
        "    plt.title('Model average training losses after each epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3Lr9o0zY7LTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "852fec7b-7465-4a37-9926-158e88c3a945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate your model by testing its ability to generate new text that resembles Shakespearean language\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "class SimpleRNNv1(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "\n",
        "    # add an embedding layer which will convert index to a raw character let's say (1 which stands for 'a') or (2 which stands for 'b') or (3 which stands for 'c') to a vector [or length vocab_size] for that character\n",
        "    self.embedding        = nn.Embedding(vocab_size, vocab_size)\n",
        "    self.lstm             = nn.LSTM(input_size=vocab_size, hidden_size=hidden_size, num_layers=3)\n",
        "    self.classifier       = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x_sequence, hidden_state):\n",
        "    # your code for RNN forward pass should take place here\n",
        "    embedded_code         = self.embedding(x_sequence)\n",
        "    output, hidden_state  = self.lstm(embedded_code, hidden_state)\n",
        "    output                = self.classifier(output)\n",
        "\n",
        "    return output, (hidden_state[0].detach(), hidden_state[1].detach())\n",
        "\n",
        "\n",
        "def test_loop(model, seed_data, sequence_length = 1000):\n",
        "\n",
        "    model.eval()          # set the model to evaluation mode for best practices\n",
        "    hidden_state          = None\n",
        "    start_index           = 0\n",
        "    iteration             = 0\n",
        "\n",
        "    # provide first few characters to initialize the hidden state\n",
        "    seed_data_length      = len(seed_data)\n",
        "    init_output, hidden_state = model(seed_data[0:seed_data_length-1], hidden_state)\n",
        "    next_input = seed_data[seed_data_length-1]\n",
        "    next_input = torch.unsqueeze(next_input, dim=0)\n",
        "\n",
        "    # predict char one letter at a time\n",
        "    for i in range(sequence_length):\n",
        "      output, hidden_state = model(next_input, hidden_state)\n",
        "      output = torch.nn.functional.softmax(torch.squeeze(output), dim=0)\n",
        "      dist   = torch.distributions.Categorical(output)\n",
        "      index  = dist.sample().item()\n",
        "      #print(\"next character prediction is: \", index_to_vocab_dict[index])\n",
        "      print(index_to_vocab_dict[index], end=\"\")\n",
        "      next_input[0] = index\n",
        "\n",
        "\n",
        "    return None\n",
        "\n",
        "# load the model\n",
        "save_path             = '/content/drive/MyDrive/cs167_sp24/datasets/rnn_model_' + file_name + '.pth'\n",
        "rnn_model             = SimpleRNNv1(vocab_size, 512, vocab_size)\n",
        "rnn_model.to(device)\n",
        "#checkpoint = torch.load(save_path, map_location=torch.device('cpu')) # loaded a trained model on 'cpu' directly\n",
        "checkpoint = torch.load(save_path, map_location=torch.device(device)) # loaded a trained model\n",
        "rnn_model.load_state_dict( checkpoint )\n",
        "\n",
        "\n",
        "# provide an initial seed text to the test_loop() method for generating next sequence of characters\n",
        "seed_text  = \"hi ther\"\n",
        "encoding   = np.zeros(len(seed_text))\n",
        "for i in range(len(seed_text)):\n",
        "  encoding[i] = vocab_to_index_dict[seed_text[i].lower()]\n",
        "for i in range(len(encoding)):\n",
        "  cur_character = index_to_vocab_dict[encoding[i]]\n",
        "  print(\"encoding: \", encoding[i], \" and the corresponding character is: \", cur_character)\n",
        "#seed_data           = torch.LongTensor(encoding) # loaded a trained model on 'cpu' directly\n",
        "seed_data           = torch.LongTensor(encoding).to(device)\n",
        "seed_data           = torch.unsqueeze(seed_data, dim=1)\n",
        "test_loop(rnn_model, seed_data, sequence_length = 1000)"
      ],
      "metadata": {
        "id": "fWm_elrgJ1Gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dcdfbe-5917-4e05-ff4e-9ef4416e5002"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoding:  20.0  and the corresponding character is:  h\n",
            "encoding:  21.0  and the corresponding character is:  i\n",
            "encoding:  1.0  and the corresponding character is:   \n",
            "encoding:  32.0  and the corresponding character is:  t\n",
            "encoding:  20.0  and the corresponding character is:  h\n",
            "encoding:  17.0  and the corresponding character is:  e\n",
            "encoding:  30.0  and the corresponding character is:  r\n",
            "e ho\n",
            "kings there.\n",
            "\n",
            "dorset:\n",
            "sweet bishop our disvince, you go.\n",
            "\n",
            "prospero:\n",
            "intonighs, all the desergs\n",
            "and roaring money, tailors!\n",
            "so having on this ann temperes; without o' to\n",
            "the king's nature of bool enough.\n",
            "\n",
            "boarina:\n",
            "i\n",
            "cannot it unto musice.\n",
            "\n",
            "sebastian:\n",
            "you are necpition o' to the gloucns,\n",
            "or go bonding to the parlo,\n",
            "drow me well: and, for they and safely me\n",
            "ang and whose preservones, hound, widows.\n",
            "\n",
            "boatswatetoe:\n",
            "\n",
            "sebastian:\n",
            "i took upon.\n",
            "\n",
            "dartensio:\n",
            "his name;\n",
            "a good sword.\n",
            "\n",
            "lord.\n",
            "\n",
            "katharina:\n",
            "now i sadferce.\n",
            "\n",
            "antonio:\n",
            "o, be food resolvens best of your affecious\n",
            "counded log! he will obse it well hath drown\n",
            "lived it.\n",
            "\n",
            "lucentio:\n",
            "not water: sir, stark; and and let me respect\n",
            "for the knees, we'll well have it not nevery green\n",
            "who i learn, i am being then, how\n",
            "you are then to match: knees the murdereon:\n",
            "therefore quoteness. couth comes most queen;\n",
            "ow what saw me ignoble,\n",
            "whom naples comes, or am, and, good lordly\n",
            "would so cold, and singing walthel, i can delighe.\n",
            "\n",
            "prospero:\n",
            "no, sits.\n",
            "\n",
            "prosp"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Group Exercise__:\n",
        "Create another RNN with 3 layers of LSTM and then train that model on a text dataset of your choice. If you can't find anything interesting you can download the following dataset and then train your RNN model on that.\n",
        "- [Download this text file -- _baby names.txt_](https://analytics.drake.edu/~reza/teaching/cs167_sp24/dataset/baby_names.txt)\n",
        "- Then, put it in your Google Drive.\n",
        "- You can also find it on Blackboard.\n",
        "  - [Reference](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/)"
      ],
      "metadata": {
        "id": "p9MmCZ0--f9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "kqJB4hncQdXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80df479-4e26-441b-a12e-5a47ae0b0729"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: load the dataset, ie, pick the dataset of your choice (baby_names or some thing else that you find interesting)\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "file_name = 'baby_names'\n",
        "path = '/content/drive/MyDrive/cs167_sp24/datasets/' + file_name + '.txt' # you can download the text file from Blackboard --> datasets\n",
        "with open(path, 'r') as file:\n",
        "  text_data = file.read() # read the entire text as a big string\n",
        "\n",
        "text_vocab = sorted(set(text_data.lower()))\n",
        "vocab_size = len(text_vocab)\n",
        "print(\"Vocabulary (referring to the alphabets present in your text data): \", text_vocab) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "print(\"Vocabulary size (referring to the alphabets present in your text data): \", vocab_size) # 'Vocabulary' refers to the alphabets present in your text data.\n",
        "print(\"\")\n",
        "text_data_size = len(text_data)\n",
        "print(\"Total number of letters (or characters) in the dataset: \", text_data_size)\n",
        "print(\"\")\n",
        "\n",
        "# First: create a mapping between the characters in our voculary to a set of numeric indices\n",
        "def convert_vocab_to_index(vocab):\n",
        "  vocab_to_index_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    vocab_to_index_dict[char] = index\n",
        "  return vocab_to_index_dict\n",
        "\n",
        "def convert_index_to_vocab(vocab):\n",
        "  index_to_vocab_dict = {}\n",
        "  for index, char in enumerate(vocab):\n",
        "    index_to_vocab_dict[index] = char\n",
        "  return index_to_vocab_dict\n",
        "\n",
        "\n",
        "vocab_to_index_dict = convert_vocab_to_index(text_vocab)\n",
        "index_to_vocab_dict = convert_index_to_vocab(text_vocab)\n",
        "\n",
        "\n",
        "# Second: convert the text_data to numeric numbers using the above conversion method (this mapped data will be used for training)\n",
        "text_data_numeric_values = np.zeros(text_data_size)\n",
        "for i in range(text_data_size):\n",
        "  cur_character = text_data[i].lower()\n",
        "  text_data_numeric_values[i] = vocab_to_index_dict[cur_character]\n",
        "\n",
        "# Third: convert to tensor datatype\n",
        "\n",
        "train_data = torch.LongTensor(text_data_numeric_values).to(device)\n",
        "train_data = torch.unsqueeze(train_data, dim=1) # make each number a separate sample for training by putting them in a separate inner list\n",
        "\n"
      ],
      "metadata": {
        "id": "chd7X5xB70Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create your RNN Network (call it SimpleRNNv1) with 1 embedding layer + 3 layers of LSTM module\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NEzPNtrrQfeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Your training and testing functions\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "Yw6a5TByQklU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: select your optimizer and set the hyper-parameters for learning the model\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "tejagPCKQztY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the training loss curve\n"
      ],
      "metadata": {
        "id": "El_YXz8Ol3Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate your model by testing its ability to generate new baby names that resembles the ones it learned from 'baby_names.txt' file\n",
        "# -------------------------------------------------------------------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J2tJeDI_NLm",
        "outputId": "5c1f4053-aefb-4bf1-b017-a406b7668e60"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoding:  11.0  and the corresponding character is:  h\n",
            "encoding:  12.0  and the corresponding character is:  i\n",
            "encoding:  1.0  and the corresponding character is:   \n",
            "encoding:  23.0  and the corresponding character is:  t\n",
            "encoding:  11.0  and the corresponding character is:  h\n",
            "encoding:  8.0  and the corresponding character is:  e\n",
            "encoding:  21.0  and the corresponding character is:  r\n",
            "\n",
            "thever\n",
            "wivlaith\n",
            "wilduth\n",
            "wilton\n",
            "wit\n",
            "wolch\n",
            "tonell\n",
            "wonette\n",
            "woney\n",
            "wovit\n",
            "wobgiel\n",
            "wogny\n",
            "woblaw\n",
            "wolfie\n",
            "wol\n",
            "wothan\n",
            "wodnaz\n",
            "wow\n",
            "woybeur\n",
            "woidaw\n",
            "woeland\n",
            "woachew\n",
            "wawby\n",
            "waibur\n",
            "wat\n",
            "waz\n",
            "ways\n",
            "tain\n",
            "wadey\n",
            "waighwin\n",
            "wuade\n",
            "wuiber\n",
            "wuedey\n",
            "vyfaid\n",
            "wianchfrinchwud\n",
            "widcher\n",
            "wiwger\n",
            "witthwoy\n",
            "wickie\n",
            "witwy\n",
            "wynah\n",
            "wistold\n",
            "wwuno\n",
            "wuine\n",
            "rwilley\n",
            "wwiotunne\n",
            "wlence\n",
            "wwonky\n",
            "vhaday\n",
            "wwode\n",
            "wir\n",
            "wirlen\n",
            "wiwn\n",
            "winy\n",
            "winwy\n",
            "wincmul\n",
            "wenthew\n",
            "winchaw\n",
            "windrick\n",
            "whonny\n",
            "wwinnard\n",
            "windhew\n",
            "wilthin\n",
            "wildon\n",
            "thole\n",
            "theb\n",
            "webliv\n",
            "bilton\n",
            "wilyo\n",
            "wilon\n",
            "wiris\n",
            "zhero\n",
            "nebbert\n",
            "wokfouut\n",
            "waodor\n",
            "wald\n",
            "waldon\n",
            "was\n",
            "walfh\n",
            "wawce\n",
            "blayke\n",
            "twos\n",
            "thiodaw\n",
            "wlefton\n",
            "wilett\n",
            "winill\n",
            "wir\n",
            "wirpie\n",
            "wirvine\n",
            "wirn\n",
            "wirvill\n",
            "twornine\n",
            "wivblil\n",
            "wimgie\n",
            "wiwclard\n",
            "wileod\n",
            "wimi ton\n",
            "thilbin\n",
            "wilson\n",
            "wylph\n",
            "wilwin\n",
            "willike\n",
            "willy\n",
            "wilmon\n",
            "wilmy\n",
            "tind\n",
            "rick\n",
            "wiwder\n",
            "wibpwel\n",
            "wit\n",
            "wyck\n",
            "widgin\n",
            "vidfawin\n",
            "wivis\n",
            "wiuuttick\n",
            "woncloin\n",
            "wownoldi\n",
            "wuudiy\n",
            "wulpine\n",
            "wuwce\n",
            "bwatten\n",
            "wyad\n",
            "wibclio\n",
            "wigobiart\n",
            "witwiav\n",
            "wilchay\n",
            "willie\n",
            "willbrotch\n",
            "willy\n",
            "wiuven\n",
            "wilen\n",
            "wiwery\n",
            "wolang\n",
            "wolin\n",
            "wyun\n",
            "winder\n",
            "winve\n",
            "wiwner\n",
            "wilgow\n",
            "wiley\n",
            "wilwer\n",
            "wilbfter\n",
            "wilner\n",
            "wilph"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}